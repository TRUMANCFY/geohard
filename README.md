<div align="center">

# __GeoHard__: Towards Measuring Class-wise Hardness through Modelling Class Semantics

</div>

> **Abstract:**
>
> Recent advances in measuring hardness-wise properties of data guide language models in sample selection within low-resource scenarios.
However, class-specific properties are overlooked for task setup and learning.
How will these properties influence model learning and is it generalizable across datasets?
To answer this question, this work formally initiates the concept of _class-wise_ _hardness_. 
Experiments across eight natural language understanding (NLU) datasets demonstrate a consistent hardness distribution across learning paradigms, models, and human judgment.
Subsequent experiments unveil a notable challenge in measuring such class-wise hardness with instance-level metrics in previous works.
To address this, we propose _GeoHard_ for class-wise hardness measurement by modeling class geometry in the semantic embedding space.
> _GeoHard_ surpasses instance-level metrics by over 59 percent on _Pearson_'s correlation on measuring class-wise hardness. 
Our analysis theoretically and empirically underscores the generality of _GeoHard_ as a fresh perspective on data diagnosis.
Additionally, we showcase how understanding class-wise hardness can practically aid in improving task learning.
>
Contact person: [Fengyu Cai](mailto:fengyu.cai@tu-darmstadt.de)

This repo contains the code of the work which will be published on ACL-2024 Finding. More details will come soon before the publication.
